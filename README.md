# etl_redshift_project

Goal of the Project
-> Get the data set (10000 rows) from public api
-> Load the data into Redshift table
-> pull the desired columns from redshift to process
-> Transform the data 
-> Load the transformed data into MySQL

Bonus:  Automating the Pipeline using CRON to run midnight (2 am) everyday
        Uses Alembic for database migrations

-> Covers SQL queries, SQLAlchemy
